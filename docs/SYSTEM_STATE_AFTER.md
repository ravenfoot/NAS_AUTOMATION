#!/usr/bin/env bash
# ==============================================================================
# ğŸ–– NAS PROJECT â€” SYSTEM STATE (AFTER)
# ==============================================================================
# Purpose:
#   Sanitised snapshot of the NAS *after* the automation project is active.
#
#   This is the "governed and observable" era:
#   - Same physical layout.
#   - A real control-plane.
#   - Stage scripts + systemd wiring.
#   - Centralised logging.
#   - Weekly drift detection against sanitised baselines.
#
# Audience:
#   Engineers or hiring managers who want proof of operational maturity,
#   not just "it works on my NAS."
#
# Path:
#   docs/SYSTEM_STATE_AFTER.md
# ==============================================================================



## ğŸ”— Related Docs

â”œâ”€â”€ START_HERE.md  
â”œâ”€â”€ ARCHITECTURE_OVERVIEW.md  
â”œâ”€â”€ SERVICE_GRAPH.md  
â”œâ”€â”€ SYSTEM_STATE_BEFORE.md  
â”œâ”€â”€ SYSTEM_STATE_AFTER.md â† You are here 
â””â”€â”€ PROJECT_JOURNEY.md  


# ğŸ›ï¸ System Identity (Sanitised)

Host: `<NAS_HOSTNAME>` (Dell Wyse 5070 Thin Client)  
OS: `<Ubuntu/Xubuntu 24.04.x LTS>`  
User: `<NAS_USER>`  

> All UUIDs, IPs, MACs, hostnames, usernames, and friendly names are sanitised. :contentReference[oaicite:16]{index=16}


# 1. ğŸ“¦ Mounts Under `/mnt`

$ sudo mount | grep /mnt
/dev/<SYS_DEVICE>     on /mnt/nas_sys_core type ext4 (...)
/dev/<BACKUP_DEVICE>  on /mnt/backup       type btrfs (...)
/dev/<MEDIA_DEVICE>   on /mnt/media        type ext4 (...)
/dev/<MEDIA2_DEVICE>  on /mnt/media_ro     type ext4 (...)
storage               on /mnt/storage      type fuse.mergerfs (...)

**Interpretation:**

Physical mounts remain consistent.

The difference is who is in charge now:
systemd + stage scripts + audit policy. 

---

# 2. ğŸ’½ Disk Layout (lsblk)

$ sudo lsblk -f
<OS_DISK>     vfat   <EFI_UUID>      /boot/efi
<OS_DISK>     ext4   <ROOT_UUID>     /
<MEDIA_DISK>  ext4   MEDIA           <MEDIA_UUID>   /mnt/media
<MEDIA2_DISK> ext4   MEDIA2          <MEDIA2_UUID>  /mnt/media_ro
<BACKUP_DISK> btrfs  BACKUP_POOL     <BACKUP_UUID>  /mnt/backup
<SYSLOG_DISK> ext4   SYSLOGS         <SYS_UUID>     /mnt/nas_sys_core


Same ship. New autopilot.

---

# 3. ğŸ“Š Filesystem Usage (df -hT)

$ sudo df -hT
/dev/<ROOT_PART>    ext4   <SIZE>  <USED>  <AVAIL>  <PCT> /
/dev/<SYS_PART>     ext4   <SIZE>  <USED>  <AVAIL>  <PCT> /mnt/nas_sys_core
/dev/<BACKUP_PART>  btrfs  <SIZE>  <USED>  <AVAIL>  <PCT> /mnt/backup
storage             fuse   <SIZE>  <USED>  <AVAIL>  <PCT> /mnt/storage


Expect slightly higher /mnt/nas_sys_core usage post-automation
due to logs + snapshots + staged backups.

---

# 4. ğŸ§¬ Btrfs Layout (Backup Pool)

$ sudo btrfs subvolume list /mnt/backup
@nas     â†’ Golden/Master config + script backups
@tower   â†’ Borg repo + health context
@logs    â†’ mirrored stage logs
@scratch â†’ safe staging zone

â€œAfterâ€ makes these subvols earn their keep on schedule.

---

# 5. ğŸŒ Network Configuration

IPs
$ sudo ip addr show
<LAN_IFACE>: <LAN_IP>/24
<wg_iface>:  <MULLVAD_IPV4>/32, <MULLVAD_IPV6>/128

Routes
$ sudo ip route
default via <LAN_GATEWAY> dev <LAN_IFACE>
<LAN_SUBNET> dev <LAN_IFACE>
<VPN_ROUTE> dev <wg_iface>

Key difference: boot-time Mullvad cloak checks
become a formal part of the boot contract.

---

# 6. ğŸ” UFW Firewall Policy (Governed State)

$ sudo ufw status verbose
Status: active
Default: deny (incoming), allow (outgoing)

LAN services allowlist (example):
- 2049/tcp+udp (NFS)
- 445/tcp (Samba)
- 8200/tcp (MiniDLNA)
- 32400/tcp (Plex)


The rules are now backed by:
stage checks + config snapshots + drift detection.

---

# 7. ğŸ§µ Open Ports Snapshot (Trimmed)

$ sudo ss -tulpen
tcp  8200   â†’ MiniDLNA
tcp  2049   â†’ NFS
tcp  32400  â†’ Plex
tcp  445    â†’ Samba
udp  1900   â†’ DLNA SSDP

Same exposure pattern, now routinely verified.

---

# 8. ğŸ§© Systemd Stage Wiring (Sanitised)

$ systemctl list-timers --all | grep nas-
nas-dlna-nightly.timer
nas-update-weekly.timer
nas-clamav-weekly.timer
nas-borg-integrity.timer
nas-audit-weekly.timer

$ systemctl status nas-boot-verify.service
$ systemctl status nas-ufw-check.service
$ systemctl status nas-mullvad-check.service


The â€œservice graphâ€ is no longer conceptual.
It is enforced by timers + dependencies.

---

# 9. ğŸ›¡ï¸ ClamAV Scan Behaviour

/mnt/nas_sys_core/logs_files/clamav.log

AV becomes a predictable weekly sweep with summarised logging.
The goal here is observability, not bloated remediation logic.

---

# 10. ğŸ§  Control-Plane (Mature Form)

/mnt/nas_sys_core/
â”œâ”€â”€ config_backups/
â”‚   â”œâ”€â”€ boot_bak/
â”‚   â”œâ”€â”€ ufw_bak/
â”‚   â”œâ”€â”€ mullvad_bak/
â”‚   â”œâ”€â”€ dlna_bak/
â”‚   â”œâ”€â”€ borg_bak/
â”‚   â”œâ”€â”€ clamav_bak/
â”‚   â”œâ”€â”€ update_bak/
â”‚   â”œâ”€â”€ shutdown_bak/
â”‚   â””â”€â”€ audit_bak/
â””â”€â”€ logs_files/
    â”œâ”€â”€ boot.log
    â”œâ”€â”€ ufw.log
    â”œâ”€â”€ mullvad.log
    â”œâ”€â”€ dlna.log
    â”œâ”€â”€ borg.log
    â”œâ”€â”€ clamav.log
    â”œâ”€â”€ update.log
    â”œâ”€â”€ audit.log
    â”œâ”€â”€ shutdown.log
    â””â”€â”€ full_core.log


This is the heart of the project:
staged reality â†’ live reality â†’ golden master.

---

**âœ¨ TL;DR**

After automation, the NAS becomes:

Modular (one script per stage)

Deterministic (systemd wiring matches declared intent)

Auditable (snapshots + weekly drift checks)

Observable (per-stage logs + full_core aggregation)

Same hardware.
A dramatically smarter nervous system.

# ==============================================================================
# ğŸ›‘ END
# ==============================================================================